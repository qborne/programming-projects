{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a44717",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 46px; font-weight: bold;\">\n",
    "  Dynamics of the implied volatility skew\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4310d3",
   "metadata": {},
   "source": [
    "## <u>STEP 1</u>: Literature Review.\n",
    "##### https://wilmott.com/managing-smile-risk/ <br> https://mfe.baruch.cuny.edu/wp-content/uploads/2013/01/OsakaSVI2012.pdf <br> https://arxiv.org/abs/1204.0646 <br> https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4428407 <br> https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4174538"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e661ad",
   "metadata": {},
   "source": [
    "## <u>STEP 2</u>: Skew Estimations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e2142-9928-4523-91e6-198f6ee54f66",
   "metadata": {},
   "source": [
    "##### The goal of this step is to compute skew values using different methods (spline, polynomial, SVI, SABR) and retain the most robust ones to obtain a reliable proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3cdc3",
   "metadata": {},
   "source": [
    "### Data Extraction & Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6563dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_vol_surface(file_path, index):\n",
    "    # Load the raw sheet\n",
    "    raw_df = pd.read_excel(file_path, sheet_name=index, header=None)\n",
    "\n",
    "    # --- Extract metadata ---\n",
    "    spot_price = float(raw_df.iloc[3, 4])          # E4\n",
    "    interest_rate = float(raw_df.iloc[1, 10])      # K2\n",
    "    dividend_rate = float(raw_df.iloc[2, 10])      # K3\n",
    "\n",
    "    # --- Extract strikes and maturities ---\n",
    "    strikes = raw_df.iloc[7, 3:12].astype(float).values             # Row 8, D to L\n",
    "    maturities = raw_df.iloc[8:21, 2].values                        # Row 9–21, Column C\n",
    "    vol_matrix = raw_df.iloc[8:21, 3:12].astype(float).values / 100.0       # Row 9–21, D to L\n",
    "\n",
    "    # --- Helper to convert maturity string to year fraction ---\n",
    "    def maturity_to_years(maturity_str):\n",
    "        if 'M' in maturity_str:\n",
    "            return int(maturity_str.replace('M', '')) / 12\n",
    "        elif 'Y' in maturity_str:\n",
    "            return int(maturity_str.replace('Y', ''))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown maturity format: {maturity_str}\")\n",
    "\n",
    "    # --- Reshape into long format ---\n",
    "    data = pd.DataFrame([\n",
    "        {\n",
    "            'maturity': maturities[i],\n",
    "            'T': maturity_to_years(maturities[i]),\n",
    "            'strike': strikes[j],\n",
    "            'moneyness': strikes[j] / spot_price,\n",
    "            'implied_vol': vol_matrix[i, j]  # Already in %\n",
    "        }\n",
    "        for i in range(len(maturities))\n",
    "        for j in range(len(strikes))\n",
    "    ])\n",
    "\n",
    "    # Add metadata\n",
    "    data['spot'] = spot_price\n",
    "    data['r'] = interest_rate\n",
    "    data['q'] = dividend_rate\n",
    "    data['index'] = index\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9bfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and print preview\n",
    "spx2014_df = load_vol_surface(file_path='market_data.xlsx', index='SPX-2014')\n",
    "spx2014_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6860a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx2015_df = load_vol_surface(file_path='market_data.xlsx', index='SPX-2015')\n",
    "ndx2014_df = load_vol_surface(file_path='market_data.xlsx', index='NDX-2014')\n",
    "ndx2015_df = load_vol_surface(file_path='market_data.xlsx', index='NDX-2015')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb61241b",
   "metadata": {},
   "source": [
    "### Quadratic Spline (like the Matlab spline function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def compute_atmf_skew_spline(df):\n",
    "    results = []\n",
    "\n",
    "    for maturity in df['maturity'].unique():\n",
    "        sub = df[df['maturity']==maturity].sort_values('strike')\n",
    "        K   = sub['strike'].values\n",
    "        σ   = sub['implied_vol'].values\n",
    "        spot, r, q = sub[['spot','r','q']].iloc[0]\n",
    "        T = sub['T'].iloc[0]\n",
    "\n",
    "        # Compute forward price\n",
    "        F = spot * np.exp((r-q)*T)\n",
    "\n",
    "        # Fit a quadratic spline (interpolates all points)\n",
    "        k = np.log(K / F) # work in log‐moneyness\n",
    "        spline_k = UnivariateSpline(k, σ, k=2, s=0)\n",
    "\n",
    "        # ∂σ/∂k at k=0\n",
    "        skew_k = spline_k.derivative()(0)\n",
    "\n",
    "        results.append({\n",
    "            'maturity': maturity,\n",
    "            'T': T,\n",
    "            'forward': F,\n",
    "            'atmf_skew': skew_k,\n",
    "            'abs_skew': abs(skew_k),\n",
    "            'index': sub['index'].iloc[0],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd29724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_spline_skew(skew_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(skew_df['T'], skew_df['abs_skew'], 'o-', color='red', label='|ATMF skew| (spline)')\n",
    "    plt.xlabel(\"Maturity (Years)\")\n",
    "    plt.ylabel(\"Absolute ATMF Skew\")\n",
    "    plt.title(f\"{skew_df['index'].iloc[0]} - Term Structure of SPX ATMF Skew (Spline Method)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spline-based ATMF skew\n",
    "spx2014_spline_skew_df = compute_atmf_skew_spline(spx2014_df)\n",
    "\n",
    "# Plot the result\n",
    "plot_spline_skew(spx2014_spline_skew_df)\n",
    "\n",
    "# look at the values\n",
    "spx2014_spline_skew_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a479d2f",
   "metadata": {},
   "source": [
    "### Quadratic Polynomial - same method than Amrani & Guyon (close to spline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf861675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.polynomial.polynomial import Polynomial\n",
    "\n",
    "def compute_atmf_skew_global_quad(df):\n",
    "    results = []\n",
    "\n",
    "    for maturity in df['maturity'].unique():\n",
    "        sub = df[df['maturity'] == maturity].sort_values('strike')\n",
    "        K   = sub['strike'].values\n",
    "        σ   = sub['implied_vol'].values\n",
    "        spot, r, q = sub[['spot','r','q']].iloc[0]\n",
    "        T = sub['T'].iloc[0]\n",
    "\n",
    "        # 1) Forward\n",
    "        F = spot * np.exp((r - q) * T)\n",
    "\n",
    "        # 2) Log-moneyness array\n",
    "        k = np.log(K / F)\n",
    "\n",
    "        # 3) Fit quadratic: σ ≈ c0 + c1·k + c2·k^2\n",
    "        #    Polynomial.fit by default maps k→[–1,1] internally, so convert() back to raw-coeffs\n",
    "        coefs = Polynomial.fit(k, σ, deg=2).convert().coef\n",
    "        c0, c1, c2 = coefs\n",
    "\n",
    "        # 4) ∂σ/∂k at k=0 is simply c1\n",
    "        skew = c1\n",
    "\n",
    "        results.append({\n",
    "            'maturity' : maturity,\n",
    "            'T'        : T,\n",
    "            'forward'  : F,\n",
    "            'atmf_skew': skew,\n",
    "            'abs_skew' : abs(skew),\n",
    "            'index'    : sub['index'].iloc[0],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6067a28-665b-48e1-ac4b-8a0d2ac8dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_global_poly_skew(skew_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(skew_df['T'], skew_df['abs_skew'], 'o-', color='orange', label='|ATMF skew| (global poly)')\n",
    "    plt.xlabel(\"Maturity (Years)\")\n",
    "    plt.ylabel(\"Absolute ATMF Skew\")\n",
    "    plt.title(f\"{skew_df['index'].iloc[0]} - Term Structure of SPX ATMF Skew (Global Quadratic Fit)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ed3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute global quadratic ATMF skew\n",
    "spx2014_poly2_skew_df = compute_atmf_skew_global_quad(spx2014_df)\n",
    "\n",
    "# Plot the result\n",
    "plot_global_poly_skew(spx2014_poly2_skew_df)\n",
    "\n",
    "# Look at the values\n",
    "spx2014_poly2_skew_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9159f",
   "metadata": {},
   "source": [
    "### Stochastic Volatility Inspired (SVI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b49dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def compute_atmf_skew_ssvi(df):\n",
    "\n",
    "    # 1) Compute forward, log-moneyness k, and total variance w\n",
    "    df['F'] = df['spot'] * np.exp((df['r'] - df['q']) * df['T'])\n",
    "    df['k'] = np.log(df['strike'] / df['F'])\n",
    "    df['w'] = df['implied_vol']**2 * df['T']\n",
    "\n",
    "    # 2) Extract ATM total variance θ(T) by picking the row with |k| closest to zero\n",
    "    theta_by_T = (\n",
    "        df\n",
    "        .assign(abs_k = df['k'].abs())        # add absolute-moneyness\n",
    "        .sort_values(['T','abs_k'])            # sort each T-slice by closeness to ATM\n",
    "        .groupby('T')['w']                     # focus on total variance column\n",
    "        .first()                               # pick the first = the ATM point\n",
    "    )\n",
    "\n",
    "    # 1) Calendar‐spread check (monotonic θ)\n",
    "    T_vals = theta_by_T.index.values\n",
    "    θ_vals = theta_by_T.values\n",
    "    if not np.all(np.diff(θ_vals) >= 0):\n",
    "        raise ValueError(\"Calendar arbitrage: θ(T) not monotonic\")\n",
    "\n",
    "    # 2) Prepare data arrays\n",
    "    k_arr   = df['k'].values\n",
    "    T_arr   = df['T'].values\n",
    "    θ_arr   = df['T'].map(theta_by_T).values\n",
    "    vol_arr = df['implied_vol'].values\n",
    "\n",
    "    # 3) SSVI slice\n",
    "    def w_ssvi(k, θ, ρ, η, γ):\n",
    "        φ = η * θ**(-γ)\n",
    "        return θ/2 * (1 + ρ*φ*k + np.sqrt((φ*k + ρ)**2 + 1 - ρ**2))\n",
    "\n",
    "    # 4) Loss in vol‐space\n",
    "    def loss(x):\n",
    "        ρ, η, γ = x\n",
    "        w_pred   = w_ssvi(k_arr, θ_arr, ρ, η, γ)\n",
    "        vol_pred = np.sqrt(w_pred / T_arr)\n",
    "        return np.mean((vol_pred - vol_arr)**2)\n",
    "\n",
    "    # 5) Build the constraints\n",
    "    cons = []\n",
    "\n",
    "    # (a) Butterfly‐free constraints for each slice\n",
    "    for θ in θ_vals:\n",
    "        cons.append({\n",
    "            'type': 'ineq',\n",
    "            'fun': lambda x, θ=θ: 4 - θ * (x[1] * θ**(-x[2])) * (1 + abs(x[0]))\n",
    "        })\n",
    "        cons.append({\n",
    "            'type': 'ineq',\n",
    "            'fun': lambda x, θ=θ: 4 - θ * (x[1] * θ**(-x[2]))**2 * (1 + abs(x[0]))\n",
    "        })\n",
    "\n",
    "    # (b) Calendar‐spread *upper* bound on ∂θ(θϕ):\n",
    "    #     (1-γ) ≤ (1+√(1-ρ²)) / ρ²\n",
    "    def shape_upper(x):\n",
    "        ρ, η, γ = x\n",
    "        # if ρ≈0 then RHS→∞, so constraint auto-satisfied\n",
    "        if abs(ρ) < 1e-6:\n",
    "            return 1e6\n",
    "        rhs = (1 + np.sqrt(1 - ρ**2)) / (ρ**2)\n",
    "        lhs = (1 - γ)\n",
    "        return rhs - lhs\n",
    "\n",
    "    cons.append({'type': 'ineq', 'fun': shape_upper})\n",
    "\n",
    "    # 6) Bounds and initial guess (ρ≠0)\n",
    "    bnds = [(-0.99, 0.99), (1e-8, None), (1e-8, 0.999)]\n",
    "    x0   = [0.2,       1.0,      0.5]    # start ρ=0.2 instead of 0\n",
    "\n",
    "    # 7) Calibrate\n",
    "    res = minimize(\n",
    "        loss,\n",
    "        x0,\n",
    "        method='SLSQP',\n",
    "        bounds=bnds,\n",
    "        constraints=cons,\n",
    "        options={'ftol':1e-12, 'maxiter':500}\n",
    "    )\n",
    "\n",
    "    if not res.success:\n",
    "        raise RuntimeError(\"SSVI calibration failed: \" + res.message)\n",
    "\n",
    "    rho, eta, gamma = res.x\n",
    "\n",
    "    # 8) Compute φ(θ) and skew ∂σ/∂k at k=0\n",
    "    phi      = eta * θ_vals**(-gamma)\n",
    "    skew     = rho * np.sqrt(θ_vals) * phi / (2 * np.sqrt(T_vals))\n",
    "    abs_skew = np.abs(skew)\n",
    "\n",
    "    # Results in DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'T': T_vals,\n",
    "        'skew': skew,\n",
    "        'abs_skew': abs_skew,\n",
    "        'index': df['index'].iloc[0],\n",
    "    })\n",
    "\n",
    "    return results.sort_values('T')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36838b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ssvi_skew(skew_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(skew_df['T'], skew_df['abs_skew'], 'o-', color='blue', label='|ATMF skew| (ssvi)')\n",
    "    plt.xlabel(\"Maturity (Years)\")\n",
    "    plt.ylabel(\"Absolute ATMF Skew\")\n",
    "    plt.title(f\"{skew_df['index'].iloc[0]} - Term Structure of SPX ATMF Skew (SSVI Method)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx2014_ssvi_skew_df = compute_atmf_skew_ssvi(spx2014_df)\n",
    "plot_ssvi_skew(spx2014_ssvi_skew_df)\n",
    "spx2014_ssvi_skew_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9c8b1",
   "metadata": {},
   "source": [
    "### Stochastic Alpha Beta Rho (SABR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc80246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def compute_atmf_skew_sabr(df, beta=1.0):\n",
    "    \"\"\"\n",
    "    For each maturity T in df, calibrate (alpha, rho, nu) to market vol smile,\n",
    "    then compute ATMF skew = ∂σ/∂k at k=0 by a small‐h finite difference of Hagan's SABR vol.\n",
    "    \"\"\"\n",
    "    def sabr_implied_vol(F, K, T, alpha, beta, rho, nu):\n",
    "        # 1) log‐moneyness\n",
    "        logFK = np.log(F / K)\n",
    "\n",
    "        # 2) FK^((1−β)/2)\n",
    "        FK_beta = (F * K)**((1 - beta) / 2)\n",
    "\n",
    "        # 3) Hagan's z‐parameter\n",
    "        z = nu / alpha * FK_beta * logFK\n",
    "\n",
    "        # 4) Prefactor and Taylor expansion in log‐moneyness\n",
    "        prefactor = alpha / FK_beta\n",
    "        term1 = 1 + (1 - beta)**2 / 24 * logFK**2 + (1 - beta)**4 / 1920 * logFK**4\n",
    "\n",
    "        # 5) Time‐dependent correction\n",
    "        corr = (\n",
    "            (1 - beta)**2 / 24 * alpha**2 / (FK_beta**2)\n",
    "            + 0.25 * rho * beta * nu * alpha / FK_beta\n",
    "            + (2 - 3 * rho**2) / 24 * nu**2\n",
    "        )\n",
    "        term2 = 1 + corr * T\n",
    "\n",
    "        # 6) z/x(z) with ATM‐limit handling and warnings muted\n",
    "        numerator = np.sqrt(1 - 2 * rho * z + z**2) + z - rho\n",
    "        denom = 1 - rho\n",
    "        x_z = np.log(numerator / denom)\n",
    "\n",
    "        tol = 1e-8\n",
    "        with np.errstate(invalid='ignore', divide='ignore'):\n",
    "            ratio = np.where(\n",
    "                np.abs(logFK) < tol,\n",
    "                1.0,        # exact ATM limit\n",
    "                z / x_z     # normal away from ATM\n",
    "            )\n",
    "\n",
    "        return prefactor * ratio * term1 * term2\n",
    "\n",
    "    # 1) prepare forwards and log‐moneyness\n",
    "    df = df.copy()\n",
    "    df['F'] = df['spot'] * np.exp((df['r'] - df['q']) * df['T'])\n",
    "    df['k'] = np.log(df['strike'] / df['F'])\n",
    "\n",
    "    results = []\n",
    "    # 2) loop through each maturity slice\n",
    "    for T, slice_df in df.groupby('T', sort=True):\n",
    "        F = slice_df['F'].iloc[0]\n",
    "        K_arr = slice_df['strike'].values\n",
    "        vol_arr = slice_df['implied_vol'].values\n",
    "\n",
    "        # initial guess: [rho, nu, alpha]\n",
    "        atm_idx = np.argmin(np.abs(np.log(K_arr / F)))\n",
    "        atm_vol = vol_arr[atm_idx]\n",
    "        x0 = [0.0, 0.5, atm_vol * F**(1 - beta)]\n",
    "        bnds = [(-0.99, 0.99), (1e-6, None), (1e-8, None)]\n",
    "\n",
    "        def loss(params):\n",
    "            rho_, nu_, alpha_ = params\n",
    "            vols = sabr_implied_vol(F, K_arr, T, alpha_, beta, rho_, nu_)\n",
    "            return np.mean((vols - vol_arr)**2)\n",
    "\n",
    "        res = minimize(\n",
    "            loss, x0, bounds=bnds, method='SLSQP',\n",
    "            options={'ftol': 1e-12, 'maxiter': 500}\n",
    "        )\n",
    "        if not res.success:\n",
    "            raise RuntimeError(f\"SABR calibration failed (T={T}): {res.message}\")\n",
    "\n",
    "        rho_opt, nu_opt, alpha_opt = res.x\n",
    "\n",
    "        # ATMF skew via central finite difference\n",
    "        h = 1e-5\n",
    "        vol_up = sabr_implied_vol(F, F * np.exp(h), T, alpha_opt, beta, rho_opt, nu_opt)\n",
    "        vol_dn = sabr_implied_vol(F, F * np.exp(-h), T, alpha_opt, beta, rho_opt, nu_opt)\n",
    "        skew = (vol_up - vol_dn) / (2 * h)\n",
    "\n",
    "        results.append({\n",
    "            'T': T,\n",
    "            'skew': skew,\n",
    "            'abs_skew': abs(skew),\n",
    "            'index': slice_df['index'].iloc[0]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02af676",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx2014_sabr_skew_df = compute_atmf_skew_sabr(spx2014_df)\n",
    "spx2014_sabr_skew_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed6e6f6",
   "metadata": {},
   "source": [
    "### Plot all skew estimations on one graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_skews(spline_df, poly_df, ssvi_df, sabr_df):\n",
    "    \"\"\"\n",
    "    spline_df : DataFrame for spline‐based skew (must have 'T' and 'abs_skew')\n",
    "    poly_df   : DataFrame for quad‐poly skew\n",
    "    ssvi_df   : DataFrame for SSVI skew\n",
    "    sabr_df   : DataFrame for SABR skew\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 1) Spline in red\n",
    "    plt.plot(\n",
    "        spline_df['T'],\n",
    "        spline_df['abs_skew'],\n",
    "        'o-',\n",
    "        color='r',\n",
    "        label='|ATMF skew| (spline)'\n",
    "    )\n",
    "\n",
    "    # 2) Quadratic polynomial in orange\n",
    "    plt.plot(\n",
    "        poly_df['T'],\n",
    "        poly_df['abs_skew'],\n",
    "        'o-',\n",
    "        color='orange',\n",
    "        label='|ATMF skew| (quad poly)'\n",
    "    )\n",
    "\n",
    "    # 3) SSVI in blue\n",
    "    plt.plot(\n",
    "        ssvi_df['T'],\n",
    "        ssvi_df['abs_skew'],\n",
    "        'o-',\n",
    "        color='b',\n",
    "        label='|ATMF skew| (SSVI)'\n",
    "    )\n",
    "\n",
    "    # 4) SABR in black\n",
    "    plt.plot(\n",
    "        sabr_df['T'],\n",
    "        sabr_df['abs_skew'],\n",
    "        'o-',\n",
    "        color='black',\n",
    "        label='|ATMF skew| (SABR)'\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Maturity (Years)\")\n",
    "    plt.ylabel(\"Absolute ATMF Skew\")\n",
    "    plt.title(f\"{spline_df['index'].iloc[0]} – Comparison of ATMF Skew Methods\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f051b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_skews(spx2014_spline_skew_df, spx2014_poly2_skew_df, spx2014_ssvi_skew_df, spx2014_sabr_skew_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d96c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPX-2015\n",
    "spx2015_spline_skew_df = compute_atmf_skew_spline(spx2015_df)\n",
    "spx2015_poly2_skew_df = compute_atmf_skew_global_quad(spx2015_df)\n",
    "spx2015_ssvi_skew_df = compute_atmf_skew_ssvi(spx2015_df)\n",
    "spx2015_sabr_skew_df = compute_atmf_skew_sabr(spx2015_df)\n",
    "\n",
    "# NDX-2014\n",
    "ndx2014_spline_skew_df = compute_atmf_skew_spline(ndx2014_df)\n",
    "ndx2014_poly2_skew_df = compute_atmf_skew_global_quad(ndx2014_df)\n",
    "ndx2014_ssvi_skew_df = compute_atmf_skew_ssvi(ndx2014_df)\n",
    "ndx2014_sabr_skew_df = compute_atmf_skew_sabr(ndx2014_df)\n",
    "\n",
    "# NDX-2015\n",
    "ndx2015_spline_skew_df = compute_atmf_skew_spline(ndx2015_df)\n",
    "ndx2015_poly2_skew_df = compute_atmf_skew_global_quad(ndx2015_df)\n",
    "ndx2015_ssvi_skew_df = compute_atmf_skew_ssvi(ndx2015_df)\n",
    "ndx2015_sabr_skew_df = compute_atmf_skew_sabr(ndx2015_df)\n",
    "\n",
    "# Plots\n",
    "plot_all_skews(spx2015_spline_skew_df, spx2015_poly2_skew_df, spx2015_ssvi_skew_df, spx2015_sabr_skew_df)\n",
    "plot_all_skews(ndx2014_spline_skew_df, ndx2014_poly2_skew_df, ndx2014_ssvi_skew_df, ndx2014_sabr_skew_df)\n",
    "plot_all_skews(ndx2015_spline_skew_df, ndx2015_poly2_skew_df, ndx2015_ssvi_skew_df, ndx2015_sabr_skew_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d0602",
   "metadata": {},
   "source": [
    "##### Based on the results from STEP 2, I decided to compute my proxy for the true skew by taking the arithmetic average of values obtained from the three most robust methods (spline, svi, and sabr), excluding the polynomial one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f685ccbc",
   "metadata": {},
   "source": [
    "## <u>STEP 3</u>: Distributional & Time Series Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2a46b",
   "metadata": {},
   "source": [
    "### Data Extraction & Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_dataset(path: str, sheet_name=0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Universal loader for SPX/SX5E‐style implied‐vol Excel sheets.\n",
    "    Returns:\n",
    "      date, maturity, T, strike, moneyness, implied_vol, spot, r, q, index\n",
    "    where `index` is the ticker prefix (e.g. \"SPX\" or \"SX5E\").\n",
    "    \"\"\"\n",
    "    # 1) Read in the raw Excel\n",
    "    df = pd.read_excel(path, sheet_name=sheet_name, header=0)\n",
    "\n",
    "    # 2) Auto‐detect the prefix via the 100% strike column\n",
    "    pfx_re = re.compile(r\"^(?P<pfx>.+?)\\s+100% MONEYNESS - U/LYING PRICE$\")\n",
    "    prefixes = { m.group(\"pfx\") for col in df.columns if (m := pfx_re.match(col)) }\n",
    "    if len(prefixes) != 1:\n",
    "        raise ValueError(f\"Expected one prefix, found: {prefixes}\")\n",
    "    prefix = prefixes.pop()\n",
    "\n",
    "    # 3) That prefix *is* our index value\n",
    "    idx_label = prefix\n",
    "\n",
    "    # 4) Pull off the 100%‐moneyness underlying price as `spot`\n",
    "    df[\"spot\"] = df[f\"{prefix} 100% MONEYNESS - U/LYING PRICE\"]\n",
    "\n",
    "    # 5) Fixed moneyness grid\n",
    "    m_vals   = [0.80,0.85,0.90,0.95,1.00,1.05,1.10,1.15,1.20]\n",
    "    pct_list = [int(m*100) for m in m_vals]\n",
    "\n",
    "    # 6) Discover all the tenor‐suffixes dynamically\n",
    "    iv_re     = re.compile(\n",
    "        rf\"^{re.escape(prefix)}\\s+\\d+% MONEYNESS - IMPLIED VOL (?P<suf>.+)$\"\n",
    "    )\n",
    "    suffixes  = { m.group(\"suf\") for col in df.columns if (m := iv_re.match(col)) }\n",
    "\n",
    "    # 7) Parse suffix → (raw_suffix, T, mat_code)\n",
    "    tenor_specs = []\n",
    "    for suf in suffixes:\n",
    "        norm  = suf.strip().rstrip(\".\")\n",
    "        parts = norm.split()\n",
    "        if len(parts)!=2: \n",
    "            continue\n",
    "        num, unit = parts\n",
    "        try:\n",
    "            num = int(num)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        if unit.upper().startswith(\"MTH\"):\n",
    "            T    = num/12\n",
    "            code = f\"{num}M\"\n",
    "        else:\n",
    "            T    = float(num)\n",
    "            code = f\"{num}Y\"\n",
    "\n",
    "        tenor_specs.append((suf, T, code))\n",
    "\n",
    "    tenor_specs.sort(key=lambda x: x[1])  # by T ascending\n",
    "\n",
    "    # 8) Build long‐form records\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        date = row[\"Dates\"]\n",
    "        s0   = row[\"spot\"]\n",
    "\n",
    "        for suf, Tval, mat in tenor_specs:\n",
    "            for pct, m in zip(pct_list, m_vals):\n",
    "                strike_col = f\"{prefix} {pct}% MONEYNESS - U/LYING PRICE\"\n",
    "                iv_col     = f\"{prefix} {pct}% MONEYNESS - IMPLIED VOL {suf}\"\n",
    "                if strike_col in row and iv_col in row:\n",
    "                    records.append({\n",
    "                        \"date\":        date,\n",
    "                        \"maturity\":    mat,\n",
    "                        \"T\":           Tval,\n",
    "                        \"strike\":      row[strike_col],\n",
    "                        \"moneyness\":   m,\n",
    "                        \"implied_vol\": row[iv_col] / 100.0,\n",
    "                        \"spot\":        s0,\n",
    "                        \"r\":           0.0,\n",
    "                        \"q\":           0.0,\n",
    "                        \"index\":      idx_label,\n",
    "                    })\n",
    "\n",
    "    # 9) Assemble and sort\n",
    "    out = pd.DataFrame.from_records(records,\n",
    "        columns=[\"date\",\"maturity\",\"T\",\n",
    "                 \"strike\",\"moneyness\",\"implied_vol\",\n",
    "                 \"spot\",\"r\",\"q\",\"index\"]\n",
    "    )\n",
    "\n",
    "    return out.sort_values([\"date\",\"T\",\"moneyness\"], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f78785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spx = load_dataset(\"dataset_spx.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaadee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sx5e = load_dataset(\"dataset_sx5e.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7404654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18baa6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sx5e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028a027",
   "metadata": {},
   "source": [
    "### Compute Proxy and fit Power Law (for specific dates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def compute_proxy(df, date, index='SPX'):\n",
    "    # 1) filter\n",
    "    sub = df[(df['date'] == date) & (df['index'] == index)].copy()\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"No data for date={date}, index={index}\")\n",
    "    \n",
    "    # 2) build each term‐structure\n",
    "    df_sp = compute_atmf_skew_spline(sub)[['T','atmf_skew']].rename(columns={'atmf_skew':'spline'})\n",
    "    df_sv = compute_atmf_skew_ssvi (sub)[['T','skew']     ].rename(columns={'skew'      :'svi'})\n",
    "    df_sb = compute_atmf_skew_sabr (sub)[['T','skew']].rename(columns={'skew':'sabr'})\n",
    "    \n",
    "    # 3) merge on T\n",
    "    df_ts = df_sp.merge(df_sv, on='T').merge(df_sb, on='T')\n",
    "    \n",
    "    # 4) proxy = simple average\n",
    "    df_ts['proxy'] = df_ts[['spline','svi','sabr']].mean(axis=1)\n",
    "\n",
    "    return df_ts.sort_values('T')\n",
    "\n",
    "def fit_powerlaw_by_minimize(T, proxy):\n",
    "    \"\"\"\n",
    "    Fit proxy ≈ A * T^{-alpha} by minimizing Σ[A T^{-α} − proxy]^2.\n",
    "    \"\"\"\n",
    "    def loss(x):\n",
    "        A, alpha = x\n",
    "        return np.sum((A * T**(-alpha) - proxy)**2)\n",
    "\n",
    "    x0   = [np.mean(proxy), 0.5]           # initial A, alpha\n",
    "    bnds = [(None, None), (0.0, None)]      # A free, alpha ≥ 0\n",
    "    res  = minimize(loss, x0, bounds=bnds, method='L-BFGS-B')\n",
    "    if not res.success:\n",
    "        raise RuntimeError(\"Power‐law fit failed: \" + res.message)\n",
    "    return res.x  # A_opt, alpha_opt\n",
    "\n",
    "def compute_proxy_and_powerlaw(df, date, index='SPX'):\n",
    "    # 1) get the spline/svi/sabr term‐structures + average proxy\n",
    "    df_ts = compute_proxy(df, date, index)   # must return cols ['T','spline','svi','sabr','proxy']\n",
    "    \n",
    "    # 2) take absolute value of the proxy (new!)\n",
    "    df_ts['proxy'] = df_ts['proxy'].abs()\n",
    "    \n",
    "    # 3) fit A, α via least‐squares minimize\n",
    "    T_vals  = df_ts['T'].values\n",
    "    proxy_v = df_ts['proxy'].values\n",
    "    A_opt, alpha_opt = fit_powerlaw_by_minimize(T_vals, proxy_v)\n",
    "\n",
    "    # 4) compute fitted curve\n",
    "    df_ts = df_ts.copy()\n",
    "    df_ts['fitted'] = A_opt * df_ts['T']**(-alpha_opt)\n",
    "\n",
    "    return df_ts.sort_values('T'), {'A': A_opt, 'alpha': alpha_opt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) compute the term‐structure for your chosen date\n",
    "df_term, params = compute_proxy_and_powerlaw(df_spx, '2011-10-03')\n",
    "\n",
    "# 2) make the plot\n",
    "plt.plot(df_term['T'], df_term['proxy'],    label='|Proxy|')\n",
    "plt.plot(df_term['T'], df_term['fitted'],  label='Fitted $A\\,T^{-\\\\alpha}$')\n",
    "plt.xlabel('Maturity $T$ (years)')\n",
    "plt.ylabel('ATMF Skew')\n",
    "plt.title('Absolute ATMF‐Skew Proxy vs. Power‐Law Fit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3) print results\n",
    "print(params)    # {'A': …, 'alpha': …}\n",
    "display(df_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) compute the term‐structure for your chosen date\n",
    "df_term, params = compute_proxy_and_powerlaw(df_spx, '2014-06-09')\n",
    "\n",
    "# 2) make the plot\n",
    "plt.plot(df_term['T'], df_term['proxy'],    label='|Proxy|')\n",
    "plt.plot(df_term['T'], df_term['fitted'],  label='Fitted $A\\,T^{-\\\\alpha}$')\n",
    "plt.xlabel('Maturity $T$ (years)')\n",
    "plt.ylabel('ATMF Skew')\n",
    "plt.title('Absolute ATMF‐Skew Proxy vs. Power‐Law Fit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3) print results\n",
    "print(params)    # {'A': …, 'alpha': …}\n",
    "display(df_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202b9a3",
   "metadata": {},
   "source": [
    "### Compute Proxy and fit Power Law (for all the Time Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def make_term_structure_ts(df, date_col='date', n_jobs=-1):\n",
    "    # ensure your date column is datetime\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "    # build (date, slice) pairs only once\n",
    "    groups = list(df.groupby(date_col))\n",
    "\n",
    "    def _process_date(date_grp):\n",
    "        date, df_date = date_grp\n",
    "        try:\n",
    "            df_term, _ = compute_proxy_and_powerlaw(df_date, date)\n",
    "            return df_term[['T','fitted']].assign(**{date_col: date})\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # run in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_process_date)(dg) for dg in groups\n",
    "    )\n",
    "\n",
    "    # stitch together\n",
    "    df_all = pd.concat(r for r in results if r is not None)\n",
    "    return (\n",
    "        df_all\n",
    "          .pivot(index=date_col, columns='T', values='fitted')\n",
    "          .sort_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bdf7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spx_ts  = make_term_structure_ts(df_spx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spx_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e43ce6",
   "metadata": {},
   "source": [
    "### Plot the Time Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237dba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maturity_label(T):\n",
    "    # if it’s already been renamed, just pass it through\n",
    "    if isinstance(T, str):\n",
    "        return T\n",
    "\n",
    "    # otherwise convert years → months and format\n",
    "    months = int(round(T * 12))\n",
    "    if months % 12 == 0:\n",
    "        return f\"{months // 12}Y\"\n",
    "    else:\n",
    "        return f\"{months}M\"\n",
    "\n",
    "df_spx_ts.rename(columns=lambda T: maturity_label(T), inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for col in df_spx_ts.columns:\n",
    "    plt.plot(df_spx_ts.index, df_spx_ts[col], label=col)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Fitted ATMF Skew\")\n",
    "plt.title(\"SPX Index - Time Series of Fitted ATMF Skew by Maturity\")\n",
    "plt.legend(title=\"Maturities (T)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0071cda",
   "metadata": {},
   "source": [
    "### Study of main distributional features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d641a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long-run mean, std, min/max, quartiles, skewness & kurtosis\n",
    "\n",
    "desc = df_spx_ts.describe().T\n",
    "desc['skew']    = df_spx_ts.skew()\n",
    "desc['kurtosis']= df_spx_ts.kurtosis()\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2ab41",
   "metadata": {},
   "source": [
    "##### ... this confirms what we observed in the first Time Series plot above: the shorter the maturity, the more important the long-term mean and the dispersion of the skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddd24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiples grid of histograms\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col in zip(axes, df_spx_ts.columns):\n",
    "    df_spx_ts[col].hist(bins=40, ax=ax)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(\"fitted skew\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c333967",
   "metadata": {},
   "source": [
    "### Study of the Time Series characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L-jung Box test for serial correlation\n",
    "    # H0: the time series is white noise\n",
    "    # H1: the time series is not white noise\n",
    "\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "lb = acorr_ljungbox(df_spx_ts['2M'], lags=[10, 20, 50, 100, 200, 500, 1000, 2500], return_df=True)\n",
    "print(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858505fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import pandas as pd\n",
    "\n",
    "# Get all maturities (columns) from df_spx_ts\n",
    "maturities = df_spx_ts.columns\n",
    "n_maturities = len(maturities)\n",
    "\n",
    "# Calculate the number of rows needed (2 plots per row)\n",
    "n_cols = 2\n",
    "n_rows = (n_maturities + 1) // 2  # Ceiling division to ensure enough rows\n",
    "\n",
    "# Create a figure with subplots (n_rows x 2)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 3 * n_rows), sharey=True)\n",
    "\n",
    "# Flatten axes array for easier iteration (in case of multiple rows)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot ACF for each maturity\n",
    "for idx, maturity in enumerate(maturities):\n",
    "    ax = axes[idx]\n",
    "    plot_acf(\n",
    "        df_spx_ts[maturity].dropna(),\n",
    "        lags=300,\n",
    "        alpha=0.05,  # 95% confidence\n",
    "        use_vlines=True,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"ACF of {maturity} Skew (95% CI)\")\n",
    "    ax.set_xlabel(\"\")  # Add x-axis label to indicate units\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')  # Rotate labels for readability\n",
    "\n",
    "# Turn off any unused subplots\n",
    "for idx in range(n_maturities, len(axes)):\n",
    "    axes[idx].axis(\"off\")\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('acf_plots_all_maturities.png', bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89708a15",
   "metadata": {},
   "source": [
    "##### According to the ACF Plots, there might be strong and persistent autocorrelation, up to around lag 150..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy.stats import norm\n",
    "\n",
    "def acf_with_pvalues(series, nlags=40, alpha=0.05):\n",
    "    # Drop any NaNs\n",
    "    x = series.dropna().values\n",
    "    n = len(x)\n",
    "    \n",
    "    # 1) Get acf and confidence intervals\n",
    "    acfs, confint = acf(x, nlags=nlags, alpha=alpha, fft=False)\n",
    "    \n",
    "    # 2) Approximate standard error under H0: rho_k=0\n",
    "    se = 1/np.sqrt(n)\n",
    "    \n",
    "    # 3) Compute two-sided p-values for each lag\n",
    "    zs = acfs / se\n",
    "    pvals = 2*(1 - norm.cdf(np.abs(zs)))\n",
    "    \n",
    "    # 4) Determine significance: if confint at lag k does not include zero\n",
    "    signif = (confint[:,0] > 0) | (confint[:,1] < 0)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'lag':        np.arange(len(acfs)),\n",
    "        'acf':        acfs,\n",
    "        'lower_ci':   confint[:,0],\n",
    "        'upper_ci':   confint[:,1],\n",
    "        'p_value':    pvals,\n",
    "        'significant': signif\n",
    "    }).set_index('lag')\n",
    "\n",
    "# Compute ACF with p-values for all maturities\n",
    "maturities = df_spx_ts.columns\n",
    "last_significant_lags = {}\n",
    "\n",
    "for maturity in maturities:\n",
    "    # Compute ACF table for the current maturity\n",
    "    acf_table = acf_with_pvalues(df_spx_ts[maturity], nlags=200)\n",
    "    \n",
    "    # Find the highest lag that remains significant at 5%\n",
    "    sig_lags = acf_table.index[acf_table['significant']]\n",
    "    last_significant_lags[maturity] = sig_lags.max() if len(sig_lags) > 0 else 0\n",
    "\n",
    "# Print only the last significant lag for each maturity\n",
    "print(\"\\nLast significant lag for each maturity:\")\n",
    "for maturity, lag in last_significant_lags.items():\n",
    "    print(f\"{maturity}: {lag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e15d2",
   "metadata": {},
   "source": [
    "##### ... which is confirmed here. This implies that past values of the skew help predict future values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e682c94",
   "metadata": {},
   "source": [
    "##### Moreover, the plot of the 3-month rolling window of the 2M skew Time Serie suggests mean-reverting behavior..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling = df_spx_ts.rolling(window=60)  # 60 trading days ~ 3mo\n",
    "roll_mean = rolling.mean()\n",
    "roll_std  = rolling.std()\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "# individual subplot titles\n",
    "roll_mean['2M'].plot(ax=ax[0], title=\"Rolling 3-mo Mean of 2M Skew\")\n",
    "roll_std ['2M'].plot(ax=ax[1], title=\"Rolling 3-mo Volatility of 2M Skew\")\n",
    "\n",
    "# super‐title for the whole figure\n",
    "fig.suptitle(\"SPX Index\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Compute rolling statistics for all maturities\n",
    "rolling = df_spx_ts.rolling(window=60)  # 60 trading days ~ 3mo\n",
    "roll_mean = rolling.mean()\n",
    "roll_std = rolling.std()\n",
    "\n",
    "# Get all maturities (columns) from df_spx_ts\n",
    "maturities = df_spx_ts.columns\n",
    "n_maturities = len(maturities)\n",
    "\n",
    "# Calculate the number of rows needed (2 plots per row, each maturity needs 2 subplots)\n",
    "n_cols = 2\n",
    "n_plots = n_maturities * 2  # Each maturity has mean and std plots\n",
    "n_rows = (n_maturities + 1) // 2 * 2  # Ceiling division, then multiply by 2 for mean and std\n",
    "\n",
    "# Create a figure with subplots (n_rows x 2)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 2.5 * n_rows), sharex=True)\n",
    "\n",
    "# Flatten axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot rolling mean and std for each maturity\n",
    "for idx, maturity in enumerate(maturities):\n",
    "    # Index for mean plot (top)\n",
    "    mean_idx = idx * 2\n",
    "    # Index for std plot (bottom)\n",
    "    std_idx = mean_idx + 1\n",
    "\n",
    "    # Plot rolling mean\n",
    "    roll_mean[maturity].plot(ax=axes[mean_idx])\n",
    "    axes[mean_idx].set_title(f\"Rolling 3-mo Mean of {maturity} Skew\")\n",
    "\n",
    "    # Plot rolling volatility\n",
    "    roll_std[maturity].plot(ax=axes[std_idx])\n",
    "    axes[std_idx].set_title(f\"Rolling 3-mo Volatility of {maturity} Skew\")\n",
    "\n",
    "# Turn off any unused subplots\n",
    "for idx in range(n_plots, len(axes)):\n",
    "    axes[idx].axis(\"off\")\n",
    "\n",
    "# Format the x-axis with date labels and units\n",
    "for ax in axes:\n",
    "    # Set major formatter to show dates in 'YYYY-MM' format\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    # Rotate labels for better readability\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    # Add x-axis label to indicate units\n",
    "    ax.set_xlabel(\"Date\")\n",
    "\n",
    "# Add a super-title for the whole figure\n",
    "fig.suptitle(\"SPX Index\", fontsize=16, y=1.02)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('rolling_stats_all_maturities.png', bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b078536",
   "metadata": {},
   "source": [
    "##### ... and the Augmented Dickey-Fuller (ADT) tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b18502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Get all maturities (columns) from df_spx_ts\n",
    "maturities = df_spx_ts.columns\n",
    "\n",
    "# Lists to store results\n",
    "results = []\n",
    "\n",
    "# Perform ADF test for each maturity\n",
    "for maturity in maturities:\n",
    "    series = df_spx_ts[maturity].dropna()\n",
    "    stat, pval, lags, nobs, crits, icbest = adfuller(series)\n",
    "    results.append({\n",
    "        'Maturity': maturity,\n",
    "        'ADF_stat': stat,\n",
    "        'p_value': pval\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results\n",
    "adf_results = pd.DataFrame(results)\n",
    "\n",
    "# Format the DataFrame for display\n",
    "adf_results['ADF_stat'] = adf_results['ADF_stat'].round(2)\n",
    "adf_results['p_value'] = adf_results['p_value'].round(3)\n",
    "adf_results.set_index('Maturity', inplace=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"\\nADF Test Results for All Maturities:\")\n",
    "print(adf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b9922",
   "metadata": {},
   "source": [
    "##### ... shows we can reject the null hypothesis (p-values < 0.05) and confirms stationarity (mean-reverting behavior) in the Time Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2b3f0",
   "metadata": {},
   "source": [
    "## <u>STEP 4</u>: Econometric Modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spx_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf43cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 1. Assume df_spx_ts is already loaded and indexed by date\n",
    "\n",
    "def test_stationarity(series, signif=0.05):\n",
    "    result = adfuller(series.dropna())\n",
    "    return result[1] < signif\n",
    "\n",
    "# 2. Difference non-stationary series and drop NaNs\n",
    "diffed = pd.DataFrame({\n",
    "    col: (df_spx_ts[col] if test_stationarity(df_spx_ts[col]) \n",
    "          else df_spx_ts[col].diff())\n",
    "    for col in df_spx_ts.columns\n",
    "}, index=df_spx_ts.index)\n",
    "diffed.dropna(inplace=True)\n",
    "\n",
    "# 3. Choose a fixed lag order on an initial window\n",
    "def select_initial_lag(data, maxlags=5):\n",
    "    try:\n",
    "        sel = VAR(data).select_order(maxlags=maxlags)\n",
    "        return int(sel.aic)\n",
    "    except Exception:\n",
    "        return 1\n",
    "\n",
    "initial_window = diffed.iloc[:750]\n",
    "fixed_lag = select_initial_lag(initial_window)\n",
    "print(f\"Fixed rolling-window lag = {fixed_lag}\")\n",
    "\n",
    "# 4. In-sample performance on initial window\n",
    "res_init = VAR(initial_window).fit(fixed_lag)\n",
    "fitted = pd.DataFrame(\n",
    "    res_init.fittedvalues,\n",
    "    index=initial_window.index[fixed_lag:],\n",
    "    columns=diffed.columns\n",
    ")\n",
    "data_in = initial_window.iloc[fixed_lag:]\n",
    "ss_res = ((data_in - fitted)**2).sum()\n",
    "ss_tot = ((data_in - data_in.mean())**2).sum()\n",
    "nobs = data_in.shape[0]\n",
    "iK = diffed.shape[1]\n",
    "n_params = iK * fixed_lag + 1\n",
    "r2 = 1 - ss_res/ss_tot\n",
    "r2_adj = 1 - (1 - r2) * (nobs - 1) / (nobs - n_params - 1)\n",
    "in_sample_perf = pd.DataFrame({'R2': r2, 'R2_adj': r2_adj})\n",
    "print(\"\\nIn-sample performance (initial window):\")\n",
    "print(in_sample_perf)\n",
    "\n",
    "# 5. Rolling-window estimation & one-step forecast for ALL maturities\n",
    "window_size = 750\n",
    "cols = list(diffed.columns)\n",
    "dates, preds, actuals = [], [], []\n",
    "\n",
    "for t in range(window_size, len(diffed)):\n",
    "    window_data = diffed.iloc[t-window_size:t]\n",
    "    dates.append(diffed.index[t])\n",
    "    actuals.append(diffed.iloc[t].values)\n",
    "    try:\n",
    "        res = VAR(window_data).fit(fixed_lag)\n",
    "        fc = res.forecast(window_data.values[-fixed_lag:], steps=1)[0]\n",
    "    except Exception:\n",
    "        fc = window_data.values[-1]\n",
    "    # clip to in-window min/max for each series\n",
    "    mins = window_data.min().values\n",
    "    maxs = window_data.max().values\n",
    "    preds.append(np.clip(fc, mins, maxs))\n",
    "\n",
    "# Build DataFrames of forecasts vs actuals\n",
    "idx = pd.to_datetime(dates)\n",
    "df_preds_all   = pd.DataFrame(preds,   index=idx, columns=cols)\n",
    "df_actuals_all = pd.DataFrame(actuals, index=idx, columns=cols)\n",
    "\n",
    "# 6. Build rolling-window error tables for 2M and 6M (unchanged)\n",
    "df_errors_2M = pd.DataFrame({\n",
    "    'Actual_2M':   df_actuals_all['2M'],\n",
    "    'Forecast_2M': df_preds_all['2M']\n",
    "}, index=idx)\n",
    "df_errors_2M['Error_2M']    = df_errors_2M['Actual_2M'] - df_errors_2M['Forecast_2M']\n",
    "df_errors_2M['AbsError_2M'] = df_errors_2M['Error_2M'].abs()\n",
    "df_errors_2M['SqError_2M']  = df_errors_2M['Error_2M']**2\n",
    "\n",
    "df_errors_6M = pd.DataFrame({\n",
    "    'Actual_6M':   df_actuals_all['6M'],\n",
    "    'Forecast_6M': df_preds_all['6M']\n",
    "}, index=idx)\n",
    "df_errors_6M['Error_6M']    = df_errors_6M['Actual_6M'] - df_errors_6M['Forecast_6M']\n",
    "df_errors_6M['AbsError_6M'] = df_errors_6M['Error_6M'].abs()\n",
    "df_errors_6M['SqError_6M']  = df_errors_6M['Error_6M']**2\n",
    "\n",
    "df_errors_combined = pd.concat([df_errors_2M, df_errors_6M], axis=1)\n",
    "print(\"\\nSample of rolling-window errors for 2M and 6M:\")\n",
    "print(df_errors_combined.head())\n",
    "\n",
    "# 7. Out-of-sample summary metrics FOR ALL MATURITIES\n",
    "df_err_all     = df_actuals_all - df_preds_all\n",
    "df_abs_err_all = df_err_all.abs()\n",
    "df_sq_err_all  = df_err_all**2\n",
    "\n",
    "rmse = np.sqrt(df_sq_err_all.mean())\n",
    "mae  = df_abs_err_all.mean()\n",
    "\n",
    "# keep 2M/6M variables for your existing prints\n",
    "e_rmse_2M = rmse['2M']\n",
    "e_mae_2M  = mae['2M']\n",
    "e_rmse_6M = rmse['6M']\n",
    "e_mae_6M  = mae['6M']\n",
    "\n",
    "out_sample_perf = pd.DataFrame({\n",
    "    'RMSE': rmse,\n",
    "    'MAE':  mae\n",
    "})\n",
    "\n",
    "print(\"\\nOut-of-sample summary metrics:\")\n",
    "print(out_sample_perf)\n",
    "\n",
    "# still print formatted 2M/6M lines\n",
    "print(f\"\\n2M RMSE: {e_rmse_2M:.4f}, MAE: {e_mae_2M:.4f}\")\n",
    "print(f\"6M RMSE: {e_rmse_6M:.4f}, MAE: {e_mae_6M:.4f}\")\n",
    "\n",
    "# 8. Plot Actual vs Forecast for full out-of-sample period for 2M and 6M\n",
    "fig_full, (ax1_full, ax2_full) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "ax1_full.plot(df_errors_2M.index, df_errors_2M['Actual_2M'], label='Actual 2M')\n",
    "ax1_full.plot(df_errors_2M.index, df_errors_2M['Forecast_2M'], '--', label='Forecasted 2M (clipped)')\n",
    "ax1_full.set_title(f'Rolling-window VAR Forecast of 2M Skew (Clipped, Full Period)\\n'\n",
    "                   f'RMSE: {e_rmse_2M:.4f}, MAE: {e_mae_2M:.4f}')\n",
    "ax1_full.legend(); ax1_full.grid(True)\n",
    "\n",
    "ax2_full.plot(df_errors_6M.index, df_errors_6M['Actual_6M'], label='Actual 6M')\n",
    "ax2_full.plot(df_errors_6M.index, df_errors_6M['Forecast_6M'], '--', label='Forecasted 6M (clipped)')\n",
    "ax2_full.set_title(f'Rolling-window VAR Forecast of 6M Skew (Clipped, Full Period)\\n'\n",
    "                   f'RMSE: {e_rmse_6M:.4f}, MAE: {e_mae_6M:.4f}')\n",
    "ax2_full.legend(); ax2_full.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Plot Actual vs Forecast from 2020+ for 2M and 6M\n",
    "results_2020_2M = df_errors_2M.loc['2020-01-01':]\n",
    "results_2020_6M = df_errors_6M.loc['2020-01-01':]\n",
    "\n",
    "fig_2020, (ax1_2020, ax2_2020) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "ax1_2020.plot(results_2020_2M.index, results_2020_2M['Actual_2M'], label='Actual 2M')\n",
    "ax1_2020.plot(results_2020_2M.index, results_2020_2M['Forecast_2M'], '--',\n",
    "               label='Forecasted 2M (clipped)')\n",
    "ax1_2020.set_title(f'Rolling-window VAR Forecast of 2M Skew (Clipped, 2020+)\\n'\n",
    "                   f'RMSE: {e_rmse_2M:.4f}, MAE: {e_mae_2M:.4f}')\n",
    "ax1_2020.legend(); ax1_2020.grid(True)\n",
    "\n",
    "ax2_2020.plot(results_2020_6M.index, results_2020_6M['Actual_6M'], label='Actual 6M')\n",
    "ax2_2020.plot(results_2020_6M.index, results_2020_6M['Forecast_6M'], '--',\n",
    "               label='Forecasted 6M (clipped)')\n",
    "ax2_2020.set_title(f'Rolling-window VAR Forecast of 6M Skew (Clipped, 2020+)\\n'\n",
    "                   f'RMSE: {e_rmse_6M:.4f}, MAE: {e_mae_6M:.4f}')\n",
    "ax2_2020.legend(); ax2_2020.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d22bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume in_sample_perf is already defined as a DataFrame with tenors as index\n",
    "# Prepare data for the table\n",
    "table_data = in_sample_perf.values\n",
    "table_data = [[f\"{val:.4f}\" for val in row] for row in table_data]  # Format numbers to 4 decimal places\n",
    "table_data = [[tenor] + list(row) for tenor, row in zip(in_sample_perf.index, table_data)]  # Add tenors as the first column\n",
    "col_labels = [\"Tenor\"] + in_sample_perf.columns.tolist()  # Include \"Tenor\" in the header\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Hide axes\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Create table\n",
    "table = ax.table(\n",
    "    cellText=table_data,\n",
    "    colLabels=col_labels,\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\",\n",
    "    colColours=[\"darkblue\"] * len(col_labels),\n",
    "    colWidths=[0.15] + [0.2] * (len(col_labels) - 1)  # Adjust column widths\n",
    ")\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.2, 2)  # Adjust table size\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    if i == 0:  # Header\n",
    "        cell.set_text_props(color=\"white\", weight=\"bold\")\n",
    "        cell.set_facecolor(\"darkblue\")\n",
    "    else:  # Cells\n",
    "        cell.set_facecolor(\"lightgrey\" if (i - 1) % 2 == 0 else \"white\")\n",
    "\n",
    "# Add title\n",
    "plt.title(\"In-sample performance (initial window)\", fontsize=20, pad=5)\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('in_sample_var_performance.png', bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume out_sample_perf is already defined as a DataFrame with tenors as index\n",
    "# Prepare data for the table\n",
    "table_data = out_sample_perf.values\n",
    "table_data = [[f\"{val:.4f}\" for val in row] for row in table_data]  # Format numbers to 4 decimal places\n",
    "table_data = [[tenor] + list(row) for tenor, row in zip(out_sample_perf.index, table_data)]  # Add tenors as the first column\n",
    "col_labels = [\"Tenor\"] + out_sample_perf.columns.tolist()  # Include \"Tenor\" in the header\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Hide axes\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Create table\n",
    "table = ax.table(\n",
    "    cellText=table_data,\n",
    "    colLabels=col_labels,\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\",\n",
    "    colColours=[\"darkblue\"] * len(col_labels),\n",
    "    colWidths=[0.15] + [0.2] * (len(col_labels) - 1)  # Adjust column widths\n",
    ")\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.2, 2)  # Adjust table size\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    if i == 0:  # Header\n",
    "        cell.set_text_props(color=\"white\", weight=\"bold\")\n",
    "        cell.set_facecolor(\"darkblue\")\n",
    "    else:  # Cells\n",
    "        cell.set_facecolor(\"lightgrey\" if (i - 1) % 2 == 0 else \"white\")\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Out-of-sample performance\", fontsize=20, pad=5)\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('out_sample_var_performance.png', bbox_inches=\"tight\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
